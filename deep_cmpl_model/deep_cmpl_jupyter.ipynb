{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_cmpl_jupyter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5YoGYWqCNbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f71f76-2444-4fa8-96a2-7e6c8583ffe7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykxVopBOEHKT"
      },
      "source": [
        "!pip install PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "downloaded = drive.CreateFile({'id':\"1XHUwpJDETylqrNJgeXRas89YswqfobG5\"})\n",
        "downloaded.GetContentFile('dataset.zip') \n",
        "!unzip \"dataset.zip\" -d \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UovUjGvQRWKK"
      },
      "source": [
        "# !unzip /content/drive/Shareddrives/Image-Text-Retrieval/dataset.zip -d /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybIFQeAjFTg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b31585-077a-479a-9c1d-2284d43baf80"
      },
      "source": [
        "!rm -rf Image_Text_Retrieval/\n",
        "%cd /content/\n",
        "!git clone --single-branch --branch main https://github.com/raghavgoyal283/Image_Text_Retrieval"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'Image_Text_Retrieval'...\n",
            "remote: Enumerating objects: 196, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (160/160), done.\u001b[K\n",
            "remote: Total 196 (delta 62), reused 159 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (196/196), 3.67 MiB | 27.82 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFd9a065q9fU",
        "outputId": "b6480f25-5c4c-4584-913e-25d3d6218d22"
      },
      "source": [
        "%cd /content/Image_Text_Retrieval\n",
        "!git pull origin main"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Image_Text_Retrieval\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 7 (delta 4), reused 7 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (7/7), done.\n",
            "From https://github.com/raghavgoyal283/Image_Text_Retrieval\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   4776f27..8b4fdaf  main       -> origin/main\n",
            "Updating 4776f27..8b4fdaf\n",
            "Fast-forward\n",
            " deep_cmpl_model/code/scripts/tester.py  | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " deep_cmpl_model/code/scripts/trainer.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 2 insertions(+), 2 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3twCZ8ABDNJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bad414d-0078-4fe5-a2e9-4e3491caefb6"
      },
      "source": [
        "%cd /content/\n",
        "!python3 /content/Image_Text_Retrieval/deep_cmpl_model/data/make_json.py\n",
        "!sh /content/Image_Text_Retrieval/deep_cmpl_model/code/datasets/data.sh"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "12305\n",
            "Preprocessing dataset\n",
            "start build vodabulary\n",
            "Total words: 1418\n",
            "Words in vocab: 812\n",
            "number of bad words: 606/1418 = 42.74%\n",
            "number of words in vocab: 812/1418 = 57.26%\n",
            "number of Null: 787/1418 = 55.50%\n",
            "Process metadata done!\n",
            "Total 9844 captions 9844 images 9844 identities in train\n",
            "Process metadata done!\n",
            "Total 1230 captions 1230 images 1230 identities in val\n",
            "Process metadata done!\n",
            "Total 1231 captions 1231 images 1231 identities in test\n",
            "Process decodedata done!\n",
            "Process decodedata done!\n",
            "Process decodedata done!\n",
            "=========== Arrange by id=============================\n",
            "Save dataset\n",
            "=========== Arrange by id=============================\n",
            "Save dataset\n",
            "=========== Arrange by id=============================\n",
            "Save dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G87T6Ntf1UOV"
      },
      "source": [
        "## Remember to push the pkl files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVxnw3Iv1QfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac403127-d98f-47fe-f288-491fb93745d1"
      },
      "source": [
        "# %cd /content/Image_Text_Retrieval\n",
        "# !git config --global user.email \"raghavgoyal283@gmail.com\"\n",
        "# !git config --global user.name \"raghavgoyal283\"\n",
        "# !git add .\n",
        "# !git commit -m \"add\"\n",
        "# !git push -u origin main"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Image_Text_Retrieval\n",
            "[anothertry af39ca4] add\n",
            " 1 file changed, 3 insertions(+), 3 deletions(-)\n",
            "Counting objects: 4, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 422 bytes | 422.00 KiB/s, done.\n",
            "Total 4 (delta 3), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/raghavgoyal283/Image_Text_Retrieval.git\n",
            "   c1d7077..af39ca4  anothertry -> anothertry\n",
            "Branch 'anothertry' set up to track remote branch 'anothertry' from 'origin'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4iFxUTlRnWQ"
      },
      "source": [
        "# Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbFhoqYkoq-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b905fe42-9ead-4887-9a77-84d62ef05db2"
      },
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/a0/dd40b50aebf0028054b6b35062948da01123d7be38d08b6b1e5435df6363/efficientnet_pytorch-0.7.1.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (1.19.5)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-cp37-none-any.whl size=16443 sha256=5a0fcea201810a6455bd03e301dc9617b6b4a66d8496abf193b0017c78d619a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/27/aa/c46d23c4e8cc72d41283862b1437e0b3ad318417e8ed7d5921\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aTdr_DrGd4x"
      },
      "source": [
        "# Clear previous checkpoints\n",
        "!rm -r /content/drive/Shareddrives/Image-Text-Retrieval/tempckpt/*"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkRKNJVcDM-F",
        "outputId": "c078b79b-bdd3-4438-b5d9-d8aa0ba129bd"
      },
      "source": [
        "%cd /content/\n",
        "!python3 /content/Image_Text_Retrieval/deep_cmpl_model/code/scripts/trainer.py"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "Total params: 17M\n",
            "epoch:0, step:0, cmpm_loss:28.980\n",
            "epoch:0, step:10, cmpm_loss:27.822\n",
            "epoch:0, step:20, cmpm_loss:25.797\n",
            "epoch:0, step:30, cmpm_loss:24.350\n",
            "epoch:0, step:40, cmpm_loss:22.872\n",
            "epoch:0, step:50, cmpm_loss:18.468\n",
            "epoch:0, step:60, cmpm_loss:17.170\n",
            "epoch:0, step:70, cmpm_loss:17.078\n",
            "epoch:0, step:80, cmpm_loss:18.581\n",
            "epoch:0, step:90, cmpm_loss:17.275\n",
            "epoch:0, step:100, cmpm_loss:16.918\n",
            "epoch:0, step:110, cmpm_loss:14.333\n",
            "epoch:0, step:120, cmpm_loss:20.252\n",
            "epoch:0, step:130, cmpm_loss:13.150\n",
            "epoch:0, step:140, cmpm_loss:13.900\n",
            "epoch:0, step:150, cmpm_loss:9.549\n",
            "epoch:0, step:160, cmpm_loss:13.966\n",
            "epoch:0, step:170, cmpm_loss:8.952\n",
            "epoch:0, step:180, cmpm_loss:10.939\n",
            "epoch:0, step:190, cmpm_loss:8.844\n",
            "epoch:0, step:200, cmpm_loss:3.907\n",
            "epoch:0, step:210, cmpm_loss:10.644\n",
            "epoch:0, step:220, cmpm_loss:10.646\n",
            "epoch:0, step:230, cmpm_loss:9.801\n",
            "epoch:0, step:240, cmpm_loss:6.492\n",
            "epoch:0, step:250, cmpm_loss:11.888\n",
            "epoch:0, step:260, cmpm_loss:16.473\n",
            "epoch:0, step:270, cmpm_loss:8.894\n",
            "epoch:0, step:280, cmpm_loss:10.306\n",
            "epoch:0, step:290, cmpm_loss:15.606\n",
            "epoch:0, step:300, cmpm_loss:7.734\n",
            "epoch:0, step:310, cmpm_loss:10.006\n",
            "epoch:0, step:320, cmpm_loss:5.520\n",
            "epoch:0, step:330, cmpm_loss:9.725\n",
            "epoch:0, step:340, cmpm_loss:8.853\n",
            "epoch:0, step:350, cmpm_loss:5.653\n",
            "epoch:0, step:360, cmpm_loss:8.572\n",
            "epoch:0, step:370, cmpm_loss:9.815\n",
            "epoch:0, step:380, cmpm_loss:6.975\n",
            "epoch:0, step:390, cmpm_loss:8.218\n",
            "epoch:0, step:400, cmpm_loss:12.703\n",
            "epoch:0, step:410, cmpm_loss:6.403\n",
            "epoch:0, step:420, cmpm_loss:7.904\n",
            "epoch:0, step:430, cmpm_loss:8.343\n",
            "epoch:0, step:440, cmpm_loss:5.121\n",
            "epoch:0, step:450, cmpm_loss:6.697\n",
            "epoch:0, step:460, cmpm_loss:8.433\n",
            "epoch:0, step:470, cmpm_loss:5.876\n",
            "epoch:0, step:480, cmpm_loss:0.763\n",
            "epoch:0, step:490, cmpm_loss:7.332\n",
            "epoch:0, step:500, cmpm_loss:13.782\n",
            "epoch:0, step:510, cmpm_loss:6.662\n",
            "epoch:0, step:520, cmpm_loss:3.625\n",
            "epoch:0, step:530, cmpm_loss:8.246\n",
            "epoch:0, step:540, cmpm_loss:7.430\n",
            "epoch:0, step:550, cmpm_loss:5.310\n",
            "epoch:0, step:560, cmpm_loss:5.444\n",
            "epoch:0, step:570, cmpm_loss:2.826\n",
            "epoch:0, step:580, cmpm_loss:4.238\n",
            "epoch:0, step:590, cmpm_loss:8.130\n",
            "epoch:0, step:600, cmpm_loss:8.824\n",
            "epoch:0, step:610, cmpm_loss:6.546\n",
            "Train done for epoch-0\n",
            "lr:0.0002\n",
            "epoch:1, step:0, cmpm_loss:6.692\n",
            "epoch:1, step:10, cmpm_loss:7.902\n",
            "epoch:1, step:20, cmpm_loss:4.313\n",
            "epoch:1, step:30, cmpm_loss:8.069\n",
            "epoch:1, step:40, cmpm_loss:3.060\n",
            "epoch:1, step:50, cmpm_loss:0.437\n",
            "epoch:1, step:60, cmpm_loss:2.161\n",
            "epoch:1, step:70, cmpm_loss:2.665\n",
            "epoch:1, step:80, cmpm_loss:9.616\n",
            "epoch:1, step:90, cmpm_loss:3.825\n",
            "epoch:1, step:100, cmpm_loss:2.910\n",
            "epoch:1, step:110, cmpm_loss:1.977\n",
            "epoch:1, step:120, cmpm_loss:1.750\n",
            "epoch:1, step:130, cmpm_loss:5.090\n",
            "epoch:1, step:140, cmpm_loss:7.062\n",
            "epoch:1, step:150, cmpm_loss:2.141\n",
            "epoch:1, step:160, cmpm_loss:7.578\n",
            "epoch:1, step:170, cmpm_loss:7.134\n",
            "epoch:1, step:180, cmpm_loss:2.916\n",
            "epoch:1, step:190, cmpm_loss:7.609\n",
            "epoch:1, step:200, cmpm_loss:2.978\n",
            "epoch:1, step:210, cmpm_loss:3.521\n",
            "epoch:1, step:220, cmpm_loss:3.619\n",
            "epoch:1, step:230, cmpm_loss:4.623\n",
            "epoch:1, step:240, cmpm_loss:6.489\n",
            "epoch:1, step:250, cmpm_loss:4.454\n",
            "epoch:1, step:260, cmpm_loss:2.816\n",
            "epoch:1, step:270, cmpm_loss:9.463\n",
            "epoch:1, step:280, cmpm_loss:3.138\n",
            "epoch:1, step:290, cmpm_loss:4.777\n",
            "epoch:1, step:300, cmpm_loss:5.296\n",
            "epoch:1, step:310, cmpm_loss:5.167\n",
            "epoch:1, step:320, cmpm_loss:4.451\n",
            "epoch:1, step:330, cmpm_loss:3.969\n",
            "epoch:1, step:340, cmpm_loss:4.741\n",
            "epoch:1, step:350, cmpm_loss:9.974\n",
            "epoch:1, step:360, cmpm_loss:7.483\n",
            "epoch:1, step:370, cmpm_loss:8.054\n",
            "epoch:1, step:380, cmpm_loss:5.053\n",
            "epoch:1, step:390, cmpm_loss:3.425\n",
            "epoch:1, step:400, cmpm_loss:2.688\n",
            "epoch:1, step:410, cmpm_loss:5.667\n",
            "epoch:1, step:420, cmpm_loss:4.761\n",
            "epoch:1, step:430, cmpm_loss:4.056\n",
            "epoch:1, step:440, cmpm_loss:6.989\n",
            "epoch:1, step:450, cmpm_loss:6.960\n",
            "epoch:1, step:460, cmpm_loss:9.581\n",
            "epoch:1, step:470, cmpm_loss:4.810\n",
            "epoch:1, step:480, cmpm_loss:4.324\n",
            "epoch:1, step:490, cmpm_loss:3.718\n",
            "epoch:1, step:500, cmpm_loss:3.811\n",
            "epoch:1, step:510, cmpm_loss:1.995\n",
            "epoch:1, step:520, cmpm_loss:5.277\n",
            "epoch:1, step:530, cmpm_loss:1.554\n",
            "epoch:1, step:540, cmpm_loss:5.259\n",
            "epoch:1, step:550, cmpm_loss:5.785\n",
            "epoch:1, step:560, cmpm_loss:7.259\n",
            "epoch:1, step:570, cmpm_loss:10.739\n",
            "epoch:1, step:580, cmpm_loss:5.838\n",
            "epoch:1, step:590, cmpm_loss:2.185\n",
            "epoch:1, step:600, cmpm_loss:4.268\n",
            "epoch:1, step:610, cmpm_loss:2.276\n",
            "Train done for epoch-1\n",
            "lr:0.0002\n",
            "epoch:2, step:0, cmpm_loss:5.452\n",
            "epoch:2, step:10, cmpm_loss:2.122\n",
            "epoch:2, step:20, cmpm_loss:10.590\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Image_Text_Retrieval/deep_cmpl_model/code/train.py\", line 230, in <module>\n",
            "    main(args)\n",
            "  File \"/content/Image_Text_Retrieval/deep_cmpl_model/code/train.py\", line 193, in main\n",
            "    train_loss, train_time = train(args.start_epoch + epoch, train_loader, network, optimizer, compute_loss, args)\n",
            "  File \"/content/Image_Text_Retrieval/deep_cmpl_model/code/train.py\", line 51, in train\n",
            "    cmpm_loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 245, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 147, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHY6hk3oFhu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7752301-3279-4969-fd58-74707300c2e6"
      },
      "source": [
        "%cd /content/\n",
        "!python3 /content/Image_Text_Retrieval/deep_cmpl_model/code/scripts/tester.py"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "==> Loading checkpoint \"drive/Shareddrives/Image-Text-Retrieval/tempckpt/data/model_data/lr-0.0002-decay-0.9-batch-16/0.pth.tar\"\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "==> Loading checkpoint \"drive/Shareddrives/Image-Text-Retrieval/tempckpt/data/model_data/lr-0.0002-decay-0.9-batch-16/1.pth.tar\"\n",
            "t2i_top1_best: 18.034, t2i_top5_best: 51.097, t2i_top10_best: 68.725, t2i_mr_best: 0.406\n",
            "i2t_top1: 17.872, i2t_top5: 49.228, i2t_top10: 67.100, i2t_mr_best: 0.487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsntUW3G_Os3"
      },
      "source": [
        "drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}